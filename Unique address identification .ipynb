{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41c51fb-ed1e-4c16-b3a8-a31c2b66183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816007f0-5aaa-45a2-bd52-be4050fe08d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = 'first_half.pickle'\n",
    "df = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a1be40-2025-4086-87b7-f5451aba6e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_number</th>\n",
       "      <th>application_number</th>\n",
       "      <th>loan_product</th>\n",
       "      <th>disbursed_date</th>\n",
       "      <th>name</th>\n",
       "      <th>applicant_type</th>\n",
       "      <th>phone</th>\n",
       "      <th>email_id</th>\n",
       "      <th>data_source</th>\n",
       "      <th>address</th>\n",
       "      <th>data_type</th>\n",
       "      <th>Date_reported</th>\n",
       "      <th>priority</th>\n",
       "      <th>address_priority</th>\n",
       "      <th>phone_priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1241680</th>\n",
       "      <td>GS096EEL1926264</td>\n",
       "      <td>A072101</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2023-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>144K KHALIPHA COLONY, BHERUPURA ROAD WAR  SIKA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229012</th>\n",
       "      <td>GS093EEL1936491</td>\n",
       "      <td>A072884</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>0 BARA ALLAHABAD BARA KHAS BARA NEAR BY BHORAW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228273</th>\n",
       "      <td>GS093EEL1548412</td>\n",
       "      <td>A044054</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>99/C MUNDERA ALLAHABAD KANPUR ROAD NEAR RK GUE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227978</th>\n",
       "      <td>GS093EEL1420229</td>\n",
       "      <td>A031833</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>HATHIGAHAN, HATHGA ALLAHABAD  PHAPHAMAU UTTAR ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213009</th>\n",
       "      <td>GS089EEL2019914</td>\n",
       "      <td>A077790</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>2/826 17 VELA AVANUE PALLADAM GANAPATHIP  TIRU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             loan_number application_number loan_product disbursed_date name  \\\n",
       "1241680  GS096EEL1926264            A072101          EEG     2023-05-28  NaN   \n",
       "1229012  GS093EEL1936491            A072884          EEG     2023-05-31  NaN   \n",
       "1228273  GS093EEL1548412            A044054          EEG     2022-12-26  NaN   \n",
       "1227978  GS093EEL1420229            A031833          EEG     2022-10-28  NaN   \n",
       "1213009  GS089EEL2019914            A077790          EEG     2023-06-30  NaN   \n",
       "\n",
       "        applicant_type phone email_id     data_source  \\\n",
       "1241680            NaN   NaN      NaN  Scrub_experian   \n",
       "1229012            NaN   NaN      NaN  Scrub_experian   \n",
       "1228273            NaN   NaN      NaN  Scrub_experian   \n",
       "1227978            NaN   NaN      NaN  Scrub_experian   \n",
       "1213009            NaN   NaN      NaN  Scrub_experian   \n",
       "\n",
       "                                                   address data_type  \\\n",
       "1241680  144K KHALIPHA COLONY, BHERUPURA ROAD WAR  SIKA...       NaN   \n",
       "1229012  0 BARA ALLAHABAD BARA KHAS BARA NEAR BY BHORAW...       NaN   \n",
       "1228273  99/C MUNDERA ALLAHABAD KANPUR ROAD NEAR RK GUE...       NaN   \n",
       "1227978  HATHIGAHAN, HATHGA ALLAHABAD  PHAPHAMAU UTTAR ...       NaN   \n",
       "1213009  2/826 17 VELA AVANUE PALLADAM GANAPATHIP  TIRU...       NaN   \n",
       "\n",
       "        Date_reported  priority  address_priority  phone_priority  \n",
       "1241680    2024-10-01         5               8.0             NaN  \n",
       "1229012    2024-10-01         5               4.0             NaN  \n",
       "1228273    2024-10-01         5               7.0             NaN  \n",
       "1227978    2024-10-01         5               5.0             NaN  \n",
       "1213009    2024-10-01         5              13.0             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875bcd72-fb2e-4ae9-8f75-abf54e0cd824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(754422, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35db862d-6cfb-4f01-a389-5c325237814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def sanitize_dataframe(df):\n",
    "    \"\"\"\n",
    "    Sanitize a DataFrame by removing illegal characters from string columns.\n",
    "    \"\"\"\n",
    "    # Regular expression for illegal characters\n",
    "    illegal_char_re = re.compile('[\\x00-\\x1f\\x7f-\\x9f]')\n",
    "\n",
    "    # Iterate over columns in DataFrame\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:  # If column is of object type (potentially strings)\n",
    "            # Remove illegal characters in the column\n",
    "            df[col] = df[col].apply(lambda x: illegal_char_re.sub('', x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "def convert_pickle_to_excel(pickle_file_path, excel_file_path):\n",
    "    # Read the pickle file\n",
    "    df = pd.read_pickle(pickle_file_path)\n",
    "    \n",
    "    # Sanitize the DataFrame\n",
    "    df_clean = sanitize_dataframe(df)\n",
    "\n",
    "    # Save the sanitized DataFrame to an Excel file\n",
    "    df_clean.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Define your pickle file path and the desired Excel file path\n",
    "pickle_file_path = 'first_half.pickle'\n",
    "excel_file_path = 'destination_file.xlsx'\n",
    "\n",
    "# Convert the pickle file to Excel\n",
    "convert_pickle_to_excel(pickle_file_path, excel_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d4bcd36-f8d6-4322-88ea-a39fd8f37115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e497a30-ceea-4629-bf23-c662f0fbf76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_number</th>\n",
       "      <th>application_number</th>\n",
       "      <th>loan_product</th>\n",
       "      <th>disbursed_date</th>\n",
       "      <th>name</th>\n",
       "      <th>applicant_type</th>\n",
       "      <th>phone</th>\n",
       "      <th>email_id</th>\n",
       "      <th>data_source</th>\n",
       "      <th>address</th>\n",
       "      <th>data_type</th>\n",
       "      <th>Date_reported</th>\n",
       "      <th>priority</th>\n",
       "      <th>address_priority</th>\n",
       "      <th>phone_priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GS096EEL1926264</td>\n",
       "      <td>A072101</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2023-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>144K KHALIPHA COLONY, BHERUPURA ROAD WAR  SIKA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GS093EEL1936491</td>\n",
       "      <td>A072884</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>0 BARA ALLAHABAD BARA KHAS BARA NEAR BY BHORAW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GS093EEL1548412</td>\n",
       "      <td>A044054</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>99/C MUNDERA ALLAHABAD KANPUR ROAD NEAR RK GUE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GS093EEL1420229</td>\n",
       "      <td>A031833</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>HATHIGAHAN, HATHGA ALLAHABAD  PHAPHAMAU UTTAR ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GS089EEL2019914</td>\n",
       "      <td>A077790</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>2/826 17 VELA AVANUE PALLADAM GANAPATHIP  TIRU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_number application_number loan_product disbursed_date name  \\\n",
       "0  GS096EEL1926264            A072101          EEG     2023-05-28  NaN   \n",
       "1  GS093EEL1936491            A072884          EEG     2023-05-31  NaN   \n",
       "2  GS093EEL1548412            A044054          EEG     2022-12-26  NaN   \n",
       "3  GS093EEL1420229            A031833          EEG     2022-10-28  NaN   \n",
       "4  GS089EEL2019914            A077790          EEG     2023-06-30  NaN   \n",
       "\n",
       "  applicant_type  phone email_id     data_source  \\\n",
       "0            NaN    NaN      NaN  Scrub_experian   \n",
       "1            NaN    NaN      NaN  Scrub_experian   \n",
       "2            NaN    NaN      NaN  Scrub_experian   \n",
       "3            NaN    NaN      NaN  Scrub_experian   \n",
       "4            NaN    NaN      NaN  Scrub_experian   \n",
       "\n",
       "                                             address data_type  \\\n",
       "0  144K KHALIPHA COLONY, BHERUPURA ROAD WAR  SIKA...       NaN   \n",
       "1  0 BARA ALLAHABAD BARA KHAS BARA NEAR BY BHORAW...       NaN   \n",
       "2  99/C MUNDERA ALLAHABAD KANPUR ROAD NEAR RK GUE...       NaN   \n",
       "3  HATHIGAHAN, HATHGA ALLAHABAD  PHAPHAMAU UTTAR ...       NaN   \n",
       "4  2/826 17 VELA AVANUE PALLADAM GANAPATHIP  TIRU...       NaN   \n",
       "\n",
       "         Date_reported  priority  address_priority  phone_priority  \n",
       "0  2024-10-01 00:00:00         5               8.0             NaN  \n",
       "1  2024-10-01 00:00:00         5               4.0             NaN  \n",
       "2  2024-10-01 00:00:00         5               7.0             NaN  \n",
       "3  2024-10-01 00:00:00         5               5.0             NaN  \n",
       "4  2024-10-01 00:00:00         5              13.0             NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d6053c-5ef6-43b4-966e-7702a957d101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(754422, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb81a66d-b4ad-4e00-b2e5-5abd6b54d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_loan_address():\n",
    "    file_path = 'destination_file.xlsx'\n",
    "    df = pd.read_excel(file_path)\n",
    "    extracted_columns = df[['loan_number', 'address']]\n",
    "    extracted_columns.to_excel('processed_addresses.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b79348b-e3b7-404e-894a-89cb0aa4daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_pincode(address):\n",
    "    if not isinstance(address, str):\n",
    "        address = \"\"\n",
    "    pincode = re.findall(r'\\d{6}', address)\n",
    "    return pincode[-1] if pincode else \"Not found\"\n",
    "\n",
    "def process_address_1():\n",
    "    excel_file = 'processed_addresses.xlsx'\n",
    "    df = pd.read_excel(excel_file)\n",
    "    df['pincode'] = df.apply(lambda row: extract_pincode(row['address']), axis=1)\n",
    "    output_file = 'processed_addresses.xlsx'\n",
    "    df.to_excel(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c536d7b9-d505-4d11-ab82-dc18d72c01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_state(address, states_array):\n",
    "    if not isinstance(address, str):\n",
    "        return \"Not Found\"\n",
    "\n",
    "    words_in_address = re.split(r'\\W+', address.upper())\n",
    "    for word in words_in_address:\n",
    "        for state in states_array:\n",
    "            if word == state.upper():\n",
    "                return state\n",
    "    return \"Not Found\"\n",
    "\n",
    "\n",
    "def process_addresses_2():\n",
    "    indian_states_and_ut = [\n",
    "        \"Andhra Pradesh\", \"Arunachal Pradesh\", \"Assam\", \"Bihar\", \"Chhattisgarh\", \"Goa\",\n",
    "        \"Gujarat\", \"Haryana\", \"Himachal Pradesh\", \"Jharkhand\", \"Karnataka\", \"Kerala\",\n",
    "        \"Madhya Pradesh\", \"Maharashtra\", \"Manipur\", \"Meghalaya\", \"Mizoram\", \"Nagaland\",\n",
    "        \"Odisha\", \"Punjab\", \"Rajasthan\", \"Sikkim\", \"Tamil Nadu\", \"Telangana\", \"Tripura\",\n",
    "        \"Uttar Pradesh\", \"Uttarakhand\", \"West Bengal\", \"Andaman and Nicobar Islands\",\n",
    "        \"Chandigarh\", \"Dadra and Nagar Haveli and Daman and Diu\", \"Lakshadweep\", \"Delhi\",\n",
    "        \"Puducherry\", \"Jammu and Kashmir\", \"Ladakh\"\n",
    "    ]\n",
    "    excel_file = 'processed_addresses.xlsx'\n",
    "    df = pd.read_excel(excel_file)\n",
    "    if 'address' in df.columns:\n",
    "        df['state'] = df.apply(lambda row: extract_state(row['address'], indian_states_and_ut), axis=1)\n",
    "    else:\n",
    "        df['state'] = \"Not Found\"\n",
    "    output_file = 'processed_addresses.xlsx'\n",
    "    df.to_excel(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86114227-0289-4692-8590-ad47edbdca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/rahul.deb/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "nltk.download('words')\n",
    "\n",
    "def extract_district(address, district_array):\n",
    "    if not isinstance(address, str):\n",
    "        return \"Not found\"\n",
    "    words_in_address = re.split(r'\\W+', address)\n",
    "    for word in words_in_address:\n",
    "        if word in district_array:\n",
    "            return word\n",
    "    return \"Not found\"\n",
    "\n",
    "def process_addresses_3():\n",
    "    district_array = ['Anantapur', 'Chittoor', 'East Godavari', 'Rajahmundry', 'Guntur', 'Krishna', 'Machilipatnam', 'Kurnool', 'Prakasam', 'Srikakulam', 'Sri Potti Sriramulu', 'Nellore', 'Visakhapatnam', 'Vizianagaram', 'West Godavari', 'Eluru', 'YSR Kadapa', 'Anjaw', 'Changlang', 'Dibang Valley', 'East Kameng', 'East Siang', 'Kurung Kumey', 'Lohit', 'Lower Dibang Valley', 'Lower Subansiri', 'Papum Pare', 'Tawang', 'Tirap', 'Upper Siang', 'Upper Subansiri', 'West Kameng', 'West Siang', 'Baksa', 'Barpeta', 'Bongaigaon', 'Cachar', 'Chirang', 'Darrang', 'Dhemaji', 'Dhubri', 'Dibrugarh', 'Dima Hasao', 'Goalpara', 'Golaghat', 'Hailakandi', 'Jorhat', 'Kamrup Metro', 'Kamrup Amingaon', 'Karimganj', 'Karbi Anglong', 'Kokrajhar', 'Lakhimpur', 'Morigaon', 'Nagaon', 'Nalbari', 'Sivasagar', 'Sonitpur', 'Tinsukia', 'Udalguri', 'Araria', 'Aurangabad', 'Banka', 'Begusarai', 'Bhagalpur', 'Bhojpur', 'Buxar', 'Darbhanga', 'East Champaran', 'Gaya', 'Gopalganj', 'Jamui', 'Jehanabad', 'Kaimur', 'Bhabhua', 'Katihar', 'Khagaria', 'Kishanganj', 'Lakhisarai', 'Madhepura', 'Madhubani', 'Munger', 'Muzaffarpur', 'Nalanda', 'Nawada', 'Patna', 'Purnea', 'Rohtas', 'Sasaram Nagar', 'Saharsa', 'Samastipur', 'Saran', 'Sheikhpura', 'Sheohar', 'Sitamarhi', 'Siwan', 'Supaul', 'Vaishali', 'West Champaran', 'Balod', 'Baloda Bazar', 'Balrampur', 'Bastar', 'Bemetara', 'Bijapur', 'Bilaspur', 'Dhamtari', 'Durg', 'Garibandh', 'Janjgir-Champa', 'Jashpur', 'Kabirdham-Kawardha', 'Kondagaon', 'Korba', 'Korea', 'Mahasamund', 'Mungeli', 'North Bastar-Kanked', 'Raigarh', 'Raipur', 'Rajnandgaon', 'South Bastar-Dantewada', 'Surajpur', 'Surguja', 'korba', 'North Goa', 'South Goa', 'Ahmedabad', 'Amreli', 'Anand', 'Aravalli', 'Banaskantha', 'Bharuch', 'Bhavnagar', 'Botad', 'Chhota Udepur', 'Dahod', 'Dang', 'Devbhumi Dwarka', 'Gandhinagar', 'Gir Somnath', 'Jamnagar', 'Junagadh', 'Kheda', 'Kutch', 'Mahisagar', 'Mehsana', 'Morbi', 'Narmada', 'Navsari', 'Panchmahals', 'Patan', 'Porbandar', 'Rajkot', 'Sabarkantha', 'Surat', 'Surendranagar', 'Tapi', 'Vadodara', 'Valsad', 'Ambala', 'Bhiwani', 'Faridabad', 'Fatehabad', 'Gurgaon', 'Hisar', 'Jhajjar', 'Jind', 'Kaithal', 'Karnal', 'Kurukshetra', 'Mahendragarh', 'Mewat', 'Palwal', 'Panchkula', 'Panipat', 'Rewari', 'Rohtak', 'Sirsa', 'Sonipat', 'Yamunanagar', 'Bilaspur', 'Chamba', 'Hamirpur', 'Kangra', 'Kinnaur', 'Kullu', 'Mandi', 'Shimla', 'Sirmaur', 'Solan', 'Una', 'Bokaro', 'Chatra', 'Deoghar', 'Dhanbad', 'Dumka', 'East Singhbhum', 'Garhwa', 'Giridih', 'Godda', 'Gumla', 'Hazaribagh', 'Jamtara', 'Khunti', 'Koderma', 'Latehar', 'Lohardaga', 'Pakur', 'Palamu', 'Ramgarh', 'Ranchi', 'Sahibganj', 'Seraikela-Kharsawan', 'Simdega', 'West Singhbhum', 'Bagalkot', 'Ballari', 'Belagavi', 'Bengaluru', 'Bengaluru Rural', 'Bidar', 'Chamrajnagar', 'Chikballapur', 'Chikkamagaluru', 'Chitradurga', 'Dakshina Kannada', 'Davangere', 'Dharwad', 'Gadag', 'Hassan', 'Haveri', 'Kalaburagi', 'Kodagu', 'Kolar', 'Koppal', 'Mandya', 'Mysuru', 'Raichur', 'Ramnagar', 'Shivamogga', 'Tumakuru', 'Udupi', 'Uttara Kannada', 'Vijayapura', 'Yadgir', 'Alappuzha', 'Ernakulam', 'Idukki', 'Kannur', 'Kasargod', 'Kollam', 'Kottayam', 'Kozhikode', 'Malappuram', 'Palakkad', 'Pathanamthitta', 'Thiruvananthapuram', 'Thrissur', 'Wayanad', 'Alirajpur', 'Anuppur', 'Ashoknagar', 'Balaghat', 'Barwani', 'Betul', 'Bhind', 'Bhopal', 'Burhanpur', 'Chhatarpur', 'Chhindwara', 'Damoh', 'Datia', 'Dewas', 'Dhar', 'Dindori', 'Guna', 'Gwalior', 'Harda', 'Hoshangabad', 'Indore', 'Jabalpur', 'Jhabua', 'Katni', 'Khandwa', 'Khargone', 'Mandla', 'Mandsaur', 'Morena', 'Narsinghpur', 'Neemuch', 'Panna', 'Raisen', 'Rajgarh', 'Ratlam', 'Rewa', 'Sagar', 'Satna', 'Sehore', 'Seoni', 'Shahdol', 'Shajapur', 'Sheopur', 'Shivpuri', 'Sidhi', 'Singrauli', 'Tikamgarh', 'Ujjain', 'Umaria', 'Vidisha', 'Ahmadnagar', 'Akola', 'Amravati', 'Aurangabad', 'Beed', 'Bhandara', 'Buldhana', 'Chandrapur', 'Dhule', 'Gadchiroli', 'Gondia', 'Jalgaon', 'Jalna', 'Kolhapur', 'Latur', 'Maharashtra CoOperative Courts', 'Maharashtra Family Courts', 'Maharashtra Industrial', 'Labour Courts', 'Mumbai City Civil Court', 'Mumbai CMM Court', 'Mumbai Motor', 'Accident Claims Tribunal', 'Mumbai Small Cause Court', 'Nagpur', 'Nanded', 'Nandurbar', 'Nashik', 'Osmanabad', 'Parbhani', 'Pune', 'Raigad', 'Ratnagiri', 'Sangli', 'Satara', 'Sindhudurg', 'Solapur', 'Thane', 'Wardha', 'Washim', 'Yavatmal', 'Mumbai', 'Bishnupur', 'Churachandpur', 'Imphal East', 'Imphal West', 'Senapati', 'Thoubal', 'Ukhrul', 'East Garo Hills', 'East Khasi Hills', 'Jaintia Hills', 'Ri-Bhoi', 'South West Garo Hills', 'West Garo Hills', 'West Khasi Hills', 'Aizawl', 'Champhai', 'Kolasib', 'Lawngtlai', 'Lunglei', 'Mamit', 'Saiha', 'Serchhip', 'Dimapur', 'Kohima', 'Kiphire', 'Longleng', 'Mokokchung', 'Mon', 'Peren', 'Phek', 'Tuensang', 'Wokha', 'Zunheboto', 'Angul', 'Balangir', 'Balasore', 'Bargarh', 'Bhadrak', 'Boudh', 'Cuttack', 'Deogarh', 'Dhenkanal', 'Gajapati', 'Ganjam', 'Jagatsinghapur', 'Jajpur', 'Jharsuguda', 'Kalahandi', 'Kandhamal', 'Kendrapara', 'Kendujhar', 'Khordha', 'Koraput', 'Malkangiri', 'Mayurbhanj', 'Nabarangpur', 'Nayagarh', 'Nuapada', 'Puri', 'Rayagada', 'Sambalpur', 'Subarnapur', 'Sundargarh', 'Amritsar', 'Barnala', 'Bathinda', 'Faridkot', 'Fatehgarh Sahib', 'Fazilka', 'Ferozepur', 'Gurdaspur', 'Hoshiarpur', 'Jalandhar', 'Kapurthala', 'Ludhiana', 'Mansa', 'Moga', 'Muktsar', 'Nawanshahr', 'Pathankot', 'Patiala', 'Rupnagar', 'Sangrur', 'SAS Nagar', 'Tarn Taran', 'Ajmer', 'Alwar', 'Banswara', 'Baran', 'Barmer', 'Bharatpur', 'Bhilwara', 'Bikaner', 'Bundi', 'Chittorgarh', 'Churu', 'Dausa', 'Dholpur', 'Dungarpur', 'Hanumangarh', 'Jaipur', 'Jaisalmer', 'Jalor', 'Jhalawar', 'Jhunjhunu', 'Jodhpur', 'Karauli', 'Kota', 'Nagaur', 'Pali', 'Pratapgarh', 'Rajsamand', 'Sawai Madhopur', 'Sikar', 'Sirohi', 'Sri Ganganagar', 'Tonk', 'Udaipur', 'East Sikkim', 'North Sikkim', 'South Sikkim', 'West Sikkim', 'Ariyalur', 'Chennai', 'Coimbatore', 'Cuddalore', 'Dharmapuri', 'Dindigul', 'Erode', 'Kanchipuram', 'Kanyakumari', 'Karur', 'Krishnagiri', 'Madurai', 'Nagapattinam', 'Namakkal', 'Perambalur', 'Pudukottai', 'Ramanathapuram', 'Salem', 'Sivaganga', 'Thanjavur', 'The Nilgiris', 'Theni', 'District Courts', 'Tiruchirappalli', 'Tirunelveni', 'Tiruppur', 'Tiruvallur', 'Tiruvannamalai', 'Tiruvarur', 'Vellore', 'Villuppuram', 'Adilabad', 'City Civil Court', 'City Small Cause Court', 'Metropolitan Sessions Court', 'Karimnagar', 'Khammam', 'Mahabubnagar', 'Medak', 'Nalgonda', 'Nizamabad', 'Ranga Reddy', 'Warangal', 'Dhalai', 'Gomati', 'Khowai', 'North Tripura', 'Sepahijala', 'South Tripura', 'Unakoti', 'West Tripura', 'Agra', 'Aligarh', 'Allahabad', 'Ambedkar Nagar', 'Amethi', 'Amroha', 'Auraiya', 'Azamgarh', 'Baghpat', 'Bahraich', 'Ballia', 'Balrampur', 'Banda', 'Barabanki', 'Bareilly', 'Basti', 'Bhadohi', 'Bijnor', 'Budaun', 'Bulandshahar', 'Chandauli', 'Chitrakoot', 'Deoria', 'Etah', 'Etawah', 'Faizabad', 'Farrukhabad', 'Fatehpur', 'Firozabad', 'Gautam Budh Nagar', 'Ghaziabad', 'Ghazipur', 'Gonda', 'Gorakhpur', 'Hamirpur', 'Hapur', 'Hardoi', 'Hathras', 'Jalaun', 'Jaunpur', 'Jhansi', 'Kannauj', 'Kanpur Dehat', 'Kanpur Nagar', 'Kasganj', 'Kaushambi', 'Kushinagar', 'Lakhimpur Kheri', 'Lalitpur', 'Lucknow', 'Maharajganj', 'Mahoba', 'Mainpuri', 'Mathura', 'Mau', 'Meerut', 'Mirzapur', 'Moradabad', 'Muzaffarnagar', 'Pilibhit', 'Pratapgarh', 'Raebareli', 'Rampur', 'Saharanpur', 'Sambhal', 'Sant Kabir Nagar', 'Shahjahanpur', 'Shamli', 'Shravasti', 'Siddhartha Nagar', 'Sitapur', 'Sonbhadra', 'Sultanpur', 'Unnao', 'Varanasi', 'Almora', 'Bageshwar', 'Chamoli', 'Champawat', 'Dehradun', 'Haridwar', 'Nainital', 'Pauri Garhwal', 'Pithoragarh', 'Rudraprayag', 'Tehri Garhwal', 'Udham Singh Nagar', 'Uttarkashi', 'Bankura', 'Birbhum', 'Cooch Behar', 'Darjeeling', 'East Bardhaman', 'East Medinipur', 'Hooghly', 'Howrah', 'Jalpaiguri', 'Kalimpong', 'Kolkata-City Civil Court', 'Kolkata-City Sessions Court', 'Kolkata-Presidency Small Causes Court', 'Malda', 'Murshidabad', 'Nadia', 'North 24 Parganas', 'North Dinajpur', 'Purulia', 'South 24 Parganas', 'South Dinajpur', 'West Bardhaman', 'West Medinipur', 'Nicobar', 'North and Middle Andaman', 'South Andaman', 'Chandigarh', 'Dadra and Nagar Haveli', 'Daman', 'Diu', 'Central Delhi', 'East Delhi', 'New Delhi', 'North Delhi', 'North East Delhi', 'North West Delhi', 'Shahdara Delhi', 'South Delhi', 'South East Delhi', 'South West Delhi', 'West Delhi', 'Anantnag', 'Badgam', 'Bandipora', 'Baramula', 'Doda', 'Ganderbal', 'Jammu', 'Kathua', 'Kishtwar', 'Kulgam', 'Kupwara', 'Poonch', 'Pulwama', 'Rajouri', 'Ramban', 'Reasi', 'Samba', 'Shopian', 'Srinagar', 'Udhampur', 'Leh', 'Kargil', 'Lakshadweep', 'Karaikal', 'Mahe', 'Pondicherry', 'Yanam']\n",
    "\n",
    "    excel_file = 'processed_addresses.xlsx'\n",
    "    df = pd.read_excel(excel_file)\n",
    "    df['district'] = df.apply(lambda row: extract_district(row['address'], district_array), axis=1)\n",
    "    output_file = 'processed_addresses.xlsx'\n",
    "    df.to_excel(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f97cda-382b-41c5-b8f2-be1363fa935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_duplicates(address):\n",
    "    words = address.split()\n",
    "    return ' '.join(sorted(set(words), key=words.index))\n",
    "\n",
    "def clean_address(address):\n",
    "    if not isinstance(address, str):\n",
    "        return address\n",
    "    address = re.sub(\"[\\/$&+,:;=?@#|'<>.^*()%!-]\", \" \", address)\n",
    "    address = re.sub(' +', ' ', address).strip()\n",
    "    address = remove_duplicates(address)\n",
    "    return address\n",
    "\n",
    "def is_address_valid(address):\n",
    "    if isinstance(cleaned_address, str):\n",
    "        # Check for minimum length\n",
    "        if len(cleaned_address) < 15:\n",
    "            return False\n",
    "\n",
    "        # Check for a minimum number of words\n",
    "        if len(cleaned_address.split()) < 5:\n",
    "            return False\n",
    "\n",
    "#         # Check if at least one of pincode, district, or state is present and valid\n",
    "#         valid_fields = [pincode, district, state]\n",
    "#         if not any(field != \"Not Found\" for field in valid_fields):\n",
    "#             return False\n",
    "\n",
    "        # Remove pincode, district, and state if they are not blank or \"Not Found\"\n",
    "        address_without_keys = cleaned_address\n",
    "        if pincode not in [\"\", \"Not Found\"]:\n",
    "            address_without_keys = address_without_keys.replace(str(pincode), '')\n",
    "        if district not in [\"\", \"Not Found\"]:\n",
    "            address_without_keys = address_without_keys.replace(district, '')\n",
    "        if state not in [\"\", \"Not Found\"]:\n",
    "            address_without_keys = address_without_keys.replace(state, '')\n",
    "\n",
    "        # Trim and check the length of the address after removals\n",
    "        address_without_keys = address_without_keys.strip()\n",
    "        if len(address_without_keys) < 7:\n",
    "            return False\n",
    "\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def process_addresses_4(file_path):\n",
    "    data = pd.read_excel(file_path, usecols=['loan_number', 'address', 'pincode', 'district', 'state'])\n",
    "    data['address_validation'] = data.apply(lambda row: 'Valid' if is_address_valid(clean_address(row['address']), row['pincode'], row['district'], row['state']) else 'Invalid', axis=1)\n",
    "    data.to_excel(file_path, index=False)\n",
    "\n",
    "def task5_execute():\n",
    "    file_path = 'processed_addresses.xlsx'\n",
    "    process_addresses_4(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1abc2dc-4b98-4326-b23f-c0b2096f77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "\n",
    "\n",
    "def normalize_address(address):\n",
    "    \"\"\"\n",
    "    Normalizes the address by removing special characters and extra spaces.\n",
    "    \"\"\"\n",
    "    if isinstance(address, str):\n",
    "        address = re.sub(r'\\s+|,|\\.|\\-', ' ', address).upper()\n",
    "        address = re.sub(\"[\\/$&+,:;=?@#|'<>.^*()%!]\", \" \", address)\n",
    "        return ' '.join(address.split())\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def fuzzy_similarity(address1, address2):\n",
    "    address1 = address1.lower()\n",
    "    address2 = address2.lower()\n",
    "    return fuzz.token_set_ratio(address1, address2)\n",
    "\n",
    "\n",
    "def fuzzy_similarity_ratio(address1, address2):\n",
    "    address1 = address1.lower()\n",
    "    address2 = address2.lower()\n",
    "    return fuzz.ratio(address1, address2)\n",
    "\n",
    "\n",
    "def extract_components(row):\n",
    "    \"\"\"\n",
    "    Extracts components like pincode, state, and district directly from the DataFrame row.\n",
    "    \"\"\"\n",
    "    pincode = row['pincode'] if pd.notnull(row['pincode']) else None\n",
    "    state = row['state'] if pd.notnull(row['state']) else None\n",
    "    district = row['district'] if pd.notnull(row['district']) else None\n",
    "    return pincode, state, district\n",
    "\n",
    "\n",
    "def is_similar_address(row1, row2, threshold=70):\n",
    "    addr1 = row1['address'].lower()\n",
    "    addr2 = row2['address'].lower()\n",
    "\n",
    "    if fuzzy_similarity(addr1, addr2) > threshold:\n",
    "        return True\n",
    "\n",
    "    if fuzz.ratio(addr1[:20], addr2[:20]) >= 80:\n",
    "        return True\n",
    "\n",
    "    if fuzzy_similarity_ratio(addr1, addr2) > threshold:\n",
    "        return True\n",
    "\n",
    "    # pattern = re.compile(r'\\b[a-zA-Z]{3,}\\b')\n",
    "    # words_addr1 = {word for word in addr1.split() if pattern.match(word)}\n",
    "    # words_addr2 = {word for word in addr2.split() if pattern.match(word)}\n",
    "    # different_words_count = len(words_addr1.symmetric_difference(words_addr2))\n",
    "    # if different_words_count > 12:\n",
    "    #     return False\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def process_addresses_5(df):\n",
    "    start_time = time.time()  # Start timing\n",
    "\n",
    "    df['Normalized_Address'] = df['address'].apply(normalize_address)\n",
    "    df['Unique_Address_ID'] = None\n",
    "    df['Merged_Pincodes'] = ''  # Initialize as empty string\n",
    "\n",
    "    loan_number_unique_addresses = {}\n",
    "    total_groups = df['loan_number'].nunique()\n",
    "    processed_groups = 0\n",
    "\n",
    "    for loan_number, group_df in df.groupby('loan_number'):\n",
    "        unique_addresses = {}\n",
    "        unique_id_counter = 1\n",
    "\n",
    "        for index, row in group_df.iterrows():\n",
    "            if row['address_validation'].lower() != 'valid':\n",
    "                continue\n",
    "\n",
    "            address = row['Normalized_Address']\n",
    "            if not address:\n",
    "                continue\n",
    "\n",
    "            address_id = None\n",
    "            for seen_address, (seen_id, seen_row) in unique_addresses.items():\n",
    "                if is_similar_address(row, seen_row):\n",
    "                    address_id = seen_id\n",
    "                    break\n",
    "\n",
    "            if address_id is None:\n",
    "                address_id = unique_id_counter\n",
    "                unique_id_counter += 1\n",
    "                unique_addresses[address] = (address_id, row)\n",
    "\n",
    "            df.loc[index, 'Unique_Address_ID'] = address_id\n",
    "\n",
    "            # Always update Merged_Pincodes for the address_id within the same loan_number\n",
    "            existing_pincodes = df[(df['loan_number'] == loan_number) & (df['Unique_Address_ID'] == address_id)][\n",
    "                'Merged_Pincodes'].unique()\n",
    "            new_pincode = str(row['pincode']) if re.match(r'^\\d{6}$', str(row['pincode'])) else ''\n",
    "            merged_pincodes = ', '.join(\n",
    "                sorted(set(filter(None, ', '.join(existing_pincodes).split(', ') + [new_pincode]))))\n",
    "            df.loc[(df['loan_number'] == loan_number) & (\n",
    "                        df['Unique_Address_ID'] == address_id), 'Merged_Pincodes'] = merged_pincodes\n",
    "\n",
    "        loan_number_unique_addresses[loan_number] = unique_addresses\n",
    "\n",
    "        processed_groups += 1\n",
    "        current_time = time.time()\n",
    "        elapsed_time = current_time - start_time\n",
    "        estimated_total_time = (elapsed_time / processed_groups) * total_groups\n",
    "        remaining_time = estimated_total_time - elapsed_time\n",
    "\n",
    "        print(\n",
    "            f\"Processed {processed_groups}/{total_groups} loan groups. Estimated time remaining: {remaining_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "    unique_addresses_data = []\n",
    "    for loan_number, addresses in loan_number_unique_addresses.items():\n",
    "        for address, (uid, addr_row) in addresses.items():\n",
    "            merged_pincodes = \\\n",
    "            df[(df['loan_number'] == loan_number) & (df['Unique_Address_ID'] == uid)]['Merged_Pincodes'].iloc[0]\n",
    "            unique_addresses_data.append({\n",
    "                'Loan_Number': loan_number,\n",
    "                'Unique_Address_ID': uid,\n",
    "                'Unique_Address': address,\n",
    "                'Merged_Pincodes': merged_pincodes\n",
    "            })\n",
    "\n",
    "    unique_df = pd.DataFrame(unique_addresses_data)\n",
    "\n",
    "    return df, unique_df\n",
    "\n",
    "\n",
    "def task6_execute():\n",
    "    file_path = 'processed_addresses.xlsx'  # Replace with your actual input file path\n",
    "    output_file_path = 'processed_addresses.xlsx'\n",
    "    unique_addresses_file_path = 'Unique_Addresses.xlsx'\n",
    "\n",
    "    df = pd.read_excel(file_path)\n",
    "    if 'loan_number' not in df.columns or 'address' not in df.columns:\n",
    "        raise ValueError(\"Excel file must contain 'loan_number' and 'address' columns\")\n",
    "\n",
    "    processed_df, unique_addresses_df = process_addresses_5(df)\n",
    "\n",
    "    processed_df.to_excel(output_file_path, index=False)\n",
    "    unique_addresses_df.to_excel(unique_addresses_file_path, index=False)\n",
    "\n",
    "    print(f\"Processed data saved to {output_file_path}\")\n",
    "    print(f\"Unique addresses saved to {unique_addresses_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8493352-2f83-4552-ad89-c40b8d7f0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    extract_loan_address()\n",
    "    process_address_1()\n",
    "    process_addresses_2()\n",
    "    process_addresses_3()\n",
    "    task5_execute()\n",
    "    #task6_execute()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9000473-23ef-4a75-a56f-1b2657ea81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6417788e-d04d-4e26-86ea-692c4c2dca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('processed_addresses.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b3d9fd6-fd24-4b15-ab01-94eeb9ddc60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_number</th>\n",
       "      <th>address</th>\n",
       "      <th>pincode</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>address_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GS096EEL1926264</td>\n",
       "      <td>144K KHALIPHA COLONY, BHERUPURA ROAD WAR  SIKA...</td>\n",
       "      <td>332001</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GS093EEL1936491</td>\n",
       "      <td>0 BARA ALLAHABAD BARA KHAS BARA NEAR BY BHORAW...</td>\n",
       "      <td>212107</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GS093EEL1548412</td>\n",
       "      <td>99/C MUNDERA ALLAHABAD KANPUR ROAD NEAR RK GUE...</td>\n",
       "      <td>211011</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GS093EEL1420229</td>\n",
       "      <td>HATHIGAHAN, HATHGA ALLAHABAD  PHAPHAMAU UTTAR ...</td>\n",
       "      <td>211013</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GS089EEL2019914</td>\n",
       "      <td>2/826 17 VELA AVANUE PALLADAM GANAPATHIP  TIRU...</td>\n",
       "      <td>641605</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_number                                            address pincode  \\\n",
       "0  GS096EEL1926264  144K KHALIPHA COLONY, BHERUPURA ROAD WAR  SIKA...  332001   \n",
       "1  GS093EEL1936491  0 BARA ALLAHABAD BARA KHAS BARA NEAR BY BHORAW...  212107   \n",
       "2  GS093EEL1548412  99/C MUNDERA ALLAHABAD KANPUR ROAD NEAR RK GUE...  211011   \n",
       "3  GS093EEL1420229  HATHIGAHAN, HATHGA ALLAHABAD  PHAPHAMAU UTTAR ...  211013   \n",
       "4  GS089EEL2019914  2/826 17 VELA AVANUE PALLADAM GANAPATHIP  TIRU...  641605   \n",
       "\n",
       "       state   district address_validation  \n",
       "0  Rajasthan  Not found              Valid  \n",
       "1  Not Found  Not found              Valid  \n",
       "2  Not Found  Not found              Valid  \n",
       "3  Not Found  Not found              Valid  \n",
       "4  Not Found  Not found              Valid  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6de86711-2b5d-4ea8-b78e-6d418c50937f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(754422, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e77cd7e5-f42d-4906-bb35-77e2292e307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "\n",
    "\n",
    "def normalize_address(address):\n",
    "    \"\"\"\n",
    "    Normalizes the address by removing special characters and extra spaces.\n",
    "    \"\"\"\n",
    "    if isinstance(address, str):\n",
    "        address = re.sub(r'\\s+|,|\\.|\\-', ' ', address).upper()\n",
    "        address = re.sub(\"[\\/$&+,:;=?@#|'<>.^*()%!]\", \" \", address)\n",
    "        return ' '.join(address.split())\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def fuzzy_similarity(address1, address2):\n",
    "    address1 = address1.lower()\n",
    "    address2 = address2.lower()\n",
    "    return fuzz.token_set_ratio(address1, address2)\n",
    "\n",
    "\n",
    "def fuzzy_similarity_ratio(address1, address2):\n",
    "    address1 = address1.lower()\n",
    "    address2 = address2.lower()\n",
    "    return fuzz.ratio(address1, address2)\n",
    "\n",
    "\n",
    "def extract_components(row):\n",
    "    \"\"\"\n",
    "    Extracts components like pincode, state, and district directly from the DataFrame row.\n",
    "    \"\"\"\n",
    "    pincode = row['pincode'] if pd.notnull(row['pincode']) else None\n",
    "    state = row['state'] if pd.notnull(row['state']) else None\n",
    "    district = row['district'] if pd.notnull(row['district']) else None\n",
    "    return pincode, state, district\n",
    "\n",
    "\n",
    "def is_similar_address(row1, row2, threshold=70):\n",
    "    addr1 = row1['address'].lower()\n",
    "    addr2 = row2['address'].lower()\n",
    "\n",
    "    if fuzzy_similarity(addr1, addr2) > threshold:\n",
    "        return True\n",
    "\n",
    "    if fuzz.ratio(addr1[:20], addr2[:20]) >= 80:\n",
    "        return True\n",
    "\n",
    "    if fuzzy_similarity_ratio(addr1, addr2) > threshold:\n",
    "        return True\n",
    "\n",
    "    # pattern = re.compile(r'\\b[a-zA-Z]{3,}\\b')\n",
    "    # words_addr1 = {word for word in addr1.split() if pattern.match(word)}\n",
    "    # words_addr2 = {word for word in addr2.split() if pattern.match(word)}\n",
    "    # different_words_count = len(words_addr1.symmetric_difference(words_addr2))\n",
    "    # if different_words_count > 12:\n",
    "    #     return False\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def process_addresses_5(df):\n",
    "    start_time = time.time()  # Start timing\n",
    "\n",
    "    df['Normalized_Address'] = df['address'].apply(normalize_address)\n",
    "    df['Unique_Address_ID'] = None\n",
    "    df['Merged_Pincodes'] = ''  # Initialize as empty string\n",
    "\n",
    "    loan_number_unique_addresses = {}\n",
    "    total_groups = df['loan_number'].nunique()\n",
    "    processed_groups = 0\n",
    "\n",
    "    for loan_number, group_df in df.groupby('loan_number'):\n",
    "        unique_addresses = {}\n",
    "        unique_id_counter = 1\n",
    "\n",
    "        for index, row in group_df.iterrows():\n",
    "            if row['address_validation'].lower() != 'valid':\n",
    "                continue\n",
    "\n",
    "            address = row['Normalized_Address']\n",
    "            if not address:\n",
    "                continue\n",
    "\n",
    "            address_id = None\n",
    "            for seen_address, (seen_id, seen_row) in unique_addresses.items():\n",
    "                if is_similar_address(row, seen_row):\n",
    "                    address_id = seen_id\n",
    "                    break\n",
    "\n",
    "            if address_id is None:\n",
    "                address_id = unique_id_counter\n",
    "                unique_id_counter += 1\n",
    "                unique_addresses[address] = (address_id, row)\n",
    "\n",
    "            df.loc[index, 'Unique_Address_ID'] = address_id\n",
    "\n",
    "            # Always update Merged_Pincodes for the address_id within the same loan_number\n",
    "            existing_pincodes = df[(df['loan_number'] == loan_number) & (df['Unique_Address_ID'] == address_id)][\n",
    "                'Merged_Pincodes'].unique()\n",
    "            new_pincode = str(row['pincode']) if re.match(r'^\\d{6}$', str(row['pincode'])) else ''\n",
    "            merged_pincodes = ', '.join(\n",
    "                sorted(set(filter(None, ', '.join(existing_pincodes).split(', ') + [new_pincode]))))\n",
    "            df.loc[(df['loan_number'] == loan_number) & (\n",
    "                        df['Unique_Address_ID'] == address_id), 'Merged_Pincodes'] = merged_pincodes\n",
    "\n",
    "        loan_number_unique_addresses[loan_number] = unique_addresses\n",
    "\n",
    "        processed_groups += 1\n",
    "        current_time = time.time()\n",
    "        elapsed_time = current_time - start_time\n",
    "        estimated_total_time = (elapsed_time / processed_groups) * total_groups\n",
    "        remaining_time = estimated_total_time - elapsed_time\n",
    "\n",
    "        print(\n",
    "            f\"Processed {processed_groups}/{total_groups} loan groups. Estimated time remaining: {remaining_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "    unique_addresses_data = []\n",
    "    for loan_number, addresses in loan_number_unique_addresses.items():\n",
    "        for address, (uid, addr_row) in addresses.items():\n",
    "            merged_pincodes = \\\n",
    "            df[(df['loan_number'] == loan_number) & (df['Unique_Address_ID'] == uid)]['Merged_Pincodes'].iloc[0]\n",
    "            unique_addresses_data.append({\n",
    "                'Loan_Number': loan_number,\n",
    "                'Unique_Address_ID': uid,\n",
    "                'Unique_Address': address,\n",
    "                'Merged_Pincodes': merged_pincodes\n",
    "            })\n",
    "\n",
    "    unique_df = pd.DataFrame(unique_addresses_data)\n",
    "\n",
    "    return df, unique_df\n",
    "\n",
    "\n",
    "def task6_execute():\n",
    "    file_path = 'processed_addresses.xlsx'  # Replace with your actual input file path\n",
    "    output_file_path = 'processed_addresses.xlsx'\n",
    "    unique_addresses_file_path = 'Unique_Addresses.xlsx'\n",
    "\n",
    "    df = pd.read_excel(file_path)\n",
    "    if 'loan_number' not in df.columns or 'address' not in df.columns:\n",
    "        raise ValueError(\"Excel file must contain 'loan_number' and 'address' columns\")\n",
    "\n",
    "    processed_df, unique_addresses_df = process_addresses_5(df)\n",
    "\n",
    "    processed_df.to_excel(output_file_path, index=False)\n",
    "    unique_addresses_df.to_excel(unique_addresses_file_path, index=False)\n",
    "\n",
    "    print(f\"Processed data saved to {output_file_path}\")\n",
    "    print(f\"Unique addresses saved to {unique_addresses_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e327945b-f437-443f-bd7d-a9323ba24833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mapply\n",
    "\n",
    "mapply.init(\n",
    "    n_workers=-1,\n",
    "    chunk_size=100,\n",
    "    max_chunks_per_worker=4,\n",
    "    progressbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d5842d8-b698-4ccb-9eab-e387a0d27e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e1357b7df04f848359ba7f58403c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Normalized_Address'] = df['address'].mapply(normalize_address)\n",
    "df['Unique_Address_ID'] = None\n",
    "df['Merged_Pincodes'] = ''  # Initialize as empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1a6f0ba-213f-40b0-b69a-50b15b1c3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique(group_df):\n",
    "    unique_addresses = {}\n",
    "    unique_id_counter = 1\n",
    "\n",
    "    for index, row in group_df.iterrows():\n",
    "        if row['address_validation'].lower() != 'valid':\n",
    "            continue\n",
    "\n",
    "        address = row['Normalized_Address']\n",
    "        if not address:\n",
    "            continue\n",
    "\n",
    "        address_id = None\n",
    "        for seen_address, (seen_id, seen_row) in unique_addresses.items():\n",
    "            if is_similar_address(row, seen_row):\n",
    "                address_id = seen_id\n",
    "                break\n",
    "\n",
    "        if address_id is None:\n",
    "            address_id = unique_id_counter\n",
    "            unique_id_counter += 1\n",
    "            unique_addresses[address] = (address_id, row)\n",
    "        \n",
    "\n",
    "        group_df.loc[index, 'Unique_Address_ID'] = address_id\n",
    "        existing_pincodes = group_df[group_df['Unique_Address_ID'] == address_id][\n",
    "            'Merged_Pincodes'].unique()\n",
    "        new_pincode = str(row['pincode']) if re.match(r'^\\d{6}$', str(row['pincode'])) else ''\n",
    "        merged_pincodes = ', '.join(\n",
    "            sorted(set(filter(None, ', '.join(existing_pincodes).split(', ') + [new_pincode]))))\n",
    "        group_df.loc[\n",
    "                    group_df['Unique_Address_ID'] == address_id, 'Merged_Pincodes'] = merged_pincodes\n",
    "\n",
    "    return group_df\n",
    "\n",
    "        # Always update Merged_Pincodes for the address_id within the same loan_number\n",
    "        # existing_pincodes = df[(df['loan_number'] == loan_number) & (df['Unique_Address_ID'] == address_id)][\n",
    "        #     'Merged_Pincodes'].unique()\n",
    "        # new_pincode = str(row['pincode']) if re.match(r'^\\d{6}$', str(row['pincode'])) else ''\n",
    "        # merged_pincodes = ', '.join(\n",
    "        #     sorted(set(filter(None, ', '.join(existing_pincodes).split(', ') + [new_pincode]))))\n",
    "        # df.loc[(df['loan_number'] == loan_number) & (\n",
    "        #             df['Unique_Address_ID'] == address_id), 'Merged_Pincodes'] = merged_pincodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d5ecd7c-90c9-4e6e-bc54-dfe82e394346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518dd87fad9c40e69f3b994a8542e49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21775 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/daily_job_analytics/rahul.deb/envs/rahul/lib/python3.11/site-packages/mapply/_groupby.py:97: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  return df_or_series.apply(func, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dfout = df.groupby('loan_number').mapply(get_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e31d4ac0-4885-43f7-904f-e9fe576e260e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(754422, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4b034f5-0fe3-4f50-9697-0747b4b071f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout.to_pickle('Address.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f87954a-1bb1-4267-a23b-e68d90b5604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rahul_unique_address_df = pd.read_pickle('first_half.pickle')\n",
    "address_df = pd.read_pickle('Address.pickle')\n",
    "\n",
    "columns_to_add = address_df[['address_validation', 'Unique_Address_ID', 'Merged_Pincodes']]\n",
    "\n",
    "rahul_unique_address_df = rahul_unique_address_df.reset_index(drop=True)\n",
    "columns_to_add = columns_to_add.reset_index(drop=True)\n",
    "\n",
    "rahul_unique_address_df = pd.concat([rahul_unique_address_df, columns_to_add], axis=1)\n",
    "\n",
    "rahul_unique_address_df.to_pickle('Rahul_April_Unique_Address_1.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07a6cd2b-e9da-4cda-9292-300c58d2327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = 'Rahul_April_Unique_Address_1.pickle'\n",
    "\n",
    "df = pd.read_pickle(pickle_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5350d676-75d8-4d63-9c9f-9aba7e93ef26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(754422, 18)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e897c8b2-0c99-403b-99ef-18a64c5e815d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_number</th>\n",
       "      <th>application_number</th>\n",
       "      <th>loan_product</th>\n",
       "      <th>disbursed_date</th>\n",
       "      <th>name</th>\n",
       "      <th>applicant_type</th>\n",
       "      <th>phone</th>\n",
       "      <th>email_id</th>\n",
       "      <th>data_source</th>\n",
       "      <th>address</th>\n",
       "      <th>data_type</th>\n",
       "      <th>Date_reported</th>\n",
       "      <th>priority</th>\n",
       "      <th>address_priority</th>\n",
       "      <th>phone_priority</th>\n",
       "      <th>address_validation</th>\n",
       "      <th>Unique_Address_ID</th>\n",
       "      <th>Merged_Pincodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GS096EEL1926264</td>\n",
       "      <td>A072101</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2023-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>144K KHALIPHA COLONY, BHERUPURA ROAD WAR  SIKA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1</td>\n",
       "      <td>332001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GS093EEL1936491</td>\n",
       "      <td>A072884</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>0 BARA ALLAHABAD BARA KHAS BARA NEAR BY BHORAW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1</td>\n",
       "      <td>212107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GS093EEL1548412</td>\n",
       "      <td>A044054</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>99/C MUNDERA ALLAHABAD KANPUR ROAD NEAR RK GUE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1</td>\n",
       "      <td>211001, 211011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GS093EEL1420229</td>\n",
       "      <td>A031833</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>HATHIGAHAN, HATHGA ALLAHABAD  PHAPHAMAU UTTAR ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1</td>\n",
       "      <td>211013, 212502, 229412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GS089EEL2019914</td>\n",
       "      <td>A077790</td>\n",
       "      <td>EEG</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrub_experian</td>\n",
       "      <td>2/826 17 VELA AVANUE PALLADAM GANAPATHIP  TIRU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1</td>\n",
       "      <td>641603, 641605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_number application_number loan_product disbursed_date name  \\\n",
       "0  GS096EEL1926264            A072101          EEG     2023-05-28  NaN   \n",
       "1  GS093EEL1936491            A072884          EEG     2023-05-31  NaN   \n",
       "2  GS093EEL1548412            A044054          EEG     2022-12-26  NaN   \n",
       "3  GS093EEL1420229            A031833          EEG     2022-10-28  NaN   \n",
       "4  GS089EEL2019914            A077790          EEG     2023-06-30  NaN   \n",
       "\n",
       "  applicant_type phone email_id     data_source  \\\n",
       "0            NaN   NaN      NaN  Scrub_experian   \n",
       "1            NaN   NaN      NaN  Scrub_experian   \n",
       "2            NaN   NaN      NaN  Scrub_experian   \n",
       "3            NaN   NaN      NaN  Scrub_experian   \n",
       "4            NaN   NaN      NaN  Scrub_experian   \n",
       "\n",
       "                                             address data_type Date_reported  \\\n",
       "0  144K KHALIPHA COLONY, BHERUPURA ROAD WAR  SIKA...       NaN    2024-10-01   \n",
       "1  0 BARA ALLAHABAD BARA KHAS BARA NEAR BY BHORAW...       NaN    2024-10-01   \n",
       "2  99/C MUNDERA ALLAHABAD KANPUR ROAD NEAR RK GUE...       NaN    2024-10-01   \n",
       "3  HATHIGAHAN, HATHGA ALLAHABAD  PHAPHAMAU UTTAR ...       NaN    2024-10-01   \n",
       "4  2/826 17 VELA AVANUE PALLADAM GANAPATHIP  TIRU...       NaN    2024-10-01   \n",
       "\n",
       "   priority  address_priority  phone_priority address_validation  \\\n",
       "0         5               8.0             NaN              Valid   \n",
       "1         5               4.0             NaN              Valid   \n",
       "2         5               7.0             NaN              Valid   \n",
       "3         5               5.0             NaN              Valid   \n",
       "4         5              13.0             NaN              Valid   \n",
       "\n",
       "  Unique_Address_ID         Merged_Pincodes  \n",
       "0                 1                  332001  \n",
       "1                 1                  212107  \n",
       "2                 1          211001, 211011  \n",
       "3                 1  211013, 212502, 229412  \n",
       "4                 1          641603, 641605  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecabb4be-1aac-4ce0-95dd-b510b7f65060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49cf1a9-b378-41f4-b00a-48c8fe93b895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
